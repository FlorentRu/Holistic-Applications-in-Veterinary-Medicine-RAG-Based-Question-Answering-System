{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57858079-9c9b-4e3c-afca-9d089359b08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "\n",
    "# Here we load the PDF file\n",
    "pdf_file = \"HolisticApplications.pdf\"\n",
    "doc = fitz.open(pdf_file)\n",
    "\n",
    "# Let's extract text from each page\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text += page.get_text()\n",
    "\n",
    "# Save the text to a file with UTF-8 encoding\n",
    "with open(\"HolisticApplications.txt\", \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f8e60-3f3e-4e84-b5d0-ed5ec4064d62",
   "metadata": {},
   "source": [
    "### Step 1: Text Preprocessing and Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59600578-d768-4589-a28d-a7b533590af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset, load_from_disk\n",
    "\n",
    "# Read and prepare text chunks\n",
    "text_chunks = [\n",
    "    {\"text\": chunk} for chunk in open(\"HolisticApplications.txt\", \"r\", encoding=\"utf-8\").read().split('\\n\\n')\n",
    "]\n",
    "\n",
    "# Convert the list of text chunks into a Hugging Face Dataset\n",
    "dataset = Dataset.from_dict({\"text\": [item['text'] for item in text_chunks]})\n",
    "\n",
    "# Save the dataset locally for indexing\n",
    "dataset.save_to_disk(\"rag_dataset\")\n",
    "\n",
    "# Load the dataset back using load_from_disk\n",
    "dataset = load_from_disk(\"rag_dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291cd4f-72e8-4b74-8123-3801adf75065",
   "metadata": {},
   "source": [
    "### Step 2: FAISS Indexing and Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82537a16-45aa-413b-aa76-23c6d9c920c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\flore\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'DPRQuestionEncoderTokenizerFast'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RagTokenizer'. \n",
      "The class this function is called from is 'BartTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the final vector array: (1, 768)\n",
      "FAISS index created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_from_disk(\"rag_dataset\")\n",
    "\n",
    "# Initialize the tokenizer and model for the RAG model\n",
    "tokenizer = RagTokenizer.from_pretrained(\"facebook/rag-token-base\")\n",
    "\n",
    "# Tokenize the text data\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Initialize FAISS index\n",
    "d = 768  # Let's take 768 as the dimension of the embeddings\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "\n",
    "# Initialize the RAG model\n",
    "rag_model = RagSequenceForGeneration.from_pretrained(\"facebook/rag-token-base\")\n",
    "encoder = rag_model.question_encoder\n",
    "\n",
    "# Convert the tokenized dataset to vectors using the encoder\n",
    "vectors = []\n",
    "\n",
    "for i, example in enumerate(tokenized_dataset):\n",
    "    input_ids = torch.tensor(example[\"input_ids\"]).unsqueeze(0)  # Add batch dimension\n",
    "    attention_mask = torch.tensor(example[\"attention_mask\"]).unsqueeze(0)\n",
    "\n",
    "    # Encode the input and get the embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        last_hidden_state = outputs[0]  # Access the first element of the output tuple\n",
    "\n",
    "        # Pick and use the hidden state as the embedding\n",
    "        embeddings = last_hidden_state\n",
    "\n",
    "        # Check if the embeddings have the correct shape\n",
    "        assert embeddings.shape == (1, d), f\"Unexpected embedding shape: {embeddings.shape}\"\n",
    "        vectors.append(embeddings.numpy())\n",
    "\n",
    "# Convert list of vectors to a numpy array and flatten the list of arrays\n",
    "vectors = np.vstack(vectors).astype(\"float32\")\n",
    "\n",
    "# Debugging: Print vector shapes\n",
    "print(f\"Shape of the final vector array: {vectors.shape}\")\n",
    "\n",
    "# Convert list of vectors to a FAISS index\n",
    "try:\n",
    "    faiss_index.add(vectors)\n",
    "    print(\"FAISS index created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during FAISS indexing: {e}\")\n",
    "\n",
    "# Save the FAISS index for later use\n",
    "faiss.write_index(faiss_index, \"holistic_applications_index.faiss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a93a8b-d44f-418c-9855-7d64de216f4d",
   "metadata": {},
   "source": [
    "### Step 3: Set Up the RAG Model and Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec53b997-c8f0-46b7-8443-d279b76dcb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RagTokenizer, RagRetriever, RagSequenceForGeneration\n",
    "\n",
    "# Load the FAISS index\n",
    "index = faiss.read_index(\"holistic_applications_index.faiss\")\n",
    "\n",
    "# Initialize the retriever\n",
    "retriever = RagRetriever.from_pretrained(\n",
    "    \"facebook/rag-token-base\",\n",
    "    index=index,\n",
    "    passages_dataset=tokenized_dataset\n",
    ")\n",
    "\n",
    "# Load the RAG model for sequence generation\n",
    "rag_model = RagSequenceForGeneration.from_pretrained(\n",
    "    \"facebook/rag-token-base\",\n",
    "    retriever=retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6f9200-090d-4e43-aea9-b5038375ee78",
   "metadata": {},
   "source": [
    "### Step 4: Build the Question-Answering Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7843b6-6066-4c83-b2da-927232c1e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the QA pipeline\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=rag_model, tokenizer=tokenizer)\n",
    "\n",
    "# Example question\n",
    "question = \"What are the benefits of holistic treatments in veterinary medicine?\"\n",
    "\n",
    "# Generate an answer\n",
    "answer = qa_pipeline(question)\n",
    "print(answer[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49e018e-9ba9-4068-a5e8-6aab004d43e0",
   "metadata": {},
   "source": [
    "### Step 5: Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29769036-6b9f-44b7-a6c8-3de286f4e461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./rag_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=rag_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_dataset,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.save_model(\"./fine_tuned_rag_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4da456-4348-42b8-9ae1-458a29063c72",
   "metadata": {},
   "source": [
    "### Step 6: Deployment and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ae609-5632-4863-b46c-a6f380f4aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "rag_model = RagSequenceForGeneration.from_pretrained(\"./fine_tuned_rag_model\")\n",
    "\n",
    "# Use the QA pipeline again with the fine-tuned model\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=rag_model, tokenizer=tokenizer)\n",
    "\n",
    "# Example question from a standard pet owner\n",
    "question = \"How effective is acupuncture for treating chronic pain in animals?\"\n",
    "\n",
    "# Generate an answer\n",
    "answer = qa_pipeline(question)\n",
    "print(answer[0]['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
